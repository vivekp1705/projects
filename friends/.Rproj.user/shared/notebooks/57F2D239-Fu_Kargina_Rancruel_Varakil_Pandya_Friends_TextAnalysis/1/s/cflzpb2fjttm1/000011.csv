"0","#Wordcloud"
"0",""
"0","used_words_df <- friends_df %>%"
"0","  unnest_tokens(word, Script, token = ""ngrams"", n = 3)"
"0",""
"0","# Remove stop words"
"0","used_words_df <- used_words_df %>%"
"0","  anti_join(stop_words)"
"0",""
"0","word_freq <- used_words_df %>%"
"0","  count(word, sort = TRUE) %>%"
"0","  na.omit()"
"0",""
"0","# Filter by frequency and select top 100"
"0","word_freq_top50 <- word_freq %>%"
"0","  filter(n >= 5) %>%"
"0","  slice_max(n = 50, order_by = n)"
"0",""
"0","wordcloud(words = word_freq_top50$word, freq = word_freq_top50$n,"
"0","          scale=c(4, 0.5), min.freq = 5, max.words=50, random.order = FALSE,"
"0","          rot.per=0.35, colors=brewer.pal(8, ""Dark2""))"
